* Modified the core-site.xml, hdfs-site.xml, mapred-site.xml, yarn-site.xml files. In hds-site, only added namenode directory in the master. And added only the datanode directoty in the slaves hdfs-site.xml. Added the java home path in hadoop-env.xml. Modified the security groups on AWS to enable communication between the Instances.

* Edited the slaves files to add the IP addresses of the slaves. Edited the masters files to add the IP address of the master. 


* Enabled passphraseless ssh between the AWS instances using (aws-harsha.pem is my pem file to access AWS instances)
eval `ssh-agent -s`
ssh-add aws-harsha.pem

* Exported the JAR file using Eclipse IDE's export feature. Configured the jar file with the class which contains the main method. So I dont have to specify the class name while running hadoop.

**************************
Oozie Installation/Build
**************************

Install Maven:

sudo apt-get install maven

Download Oozie-4.1.0

wget http://archive.apache.org/dist/oozie/4.1.0/oozie-4.1.0.tar.gz

Untar

sudo tar xvzf oozie-4.1.0.tar.gz

cd oozie-4.1.0

sudo bin/mkdistro.sh -DskipTests -Dhadoopversion=2.6.0

mkdir ~/oozie-4.1

cp -R distro/target/oozie-4.1.0-distro/oozie-4.1.0/* ~/oozie-4.1

# edit /etc/profile 
sudo vim /etc/profile

    export OOZIE_VERSION=4.1.0
    export OOZIE_HOME=/home/anggao/oozie-4.1
    export PATH=$PATH:$OOZIE_HOME/bin

source /etc/profile

# enable web console for Oozie

# we need ext-*.*.zip library and extjs

cd $OOZIE_HOME

mkdir libext

cp ../oozie-4.1.0/hadooplibs/target/oozie-4.1.0-hadooplibs.tar.gz .

tar -xzvf oozie-4.1.0-hadooplibs.tar.gz

cp oozie-4.1.0/hadooplibs/hadooplib-2.3.0.oozie-4.1.0/* libext

cd libext/

wget http://archive.cloudera.com/gplextras/misc/ext-2.2.zip

# Configure the Hadoop cluster with proxyuser for the Oozie process.
# The following two properties are required in Hadoop core-site.xml:

  <!-- OOZIE -->
  <property>
      <name>hadoop.proxyuser.ubuntu.hosts</name>
      <value>*</value>
  </property>
  <property>
      <name>hadoop.proxyuser.ubuntu.groups</name>
      <value>*</value>
  </property>

## RESTART HADOOP CLUSTER  !! ###

sudo apt-get install unzip

sudo apt-get intall zip

oozie-setup.sh prepare-war

# Create Sharelib Directory on HDFS

# first get HDFS info
hdfs getconf -confKey fs.defaultFS

-->hdfs://ec2-52-91-50-127.compute-1.amazonaws.com:9000

# use the info obtained above
oozie-setup.sh sharelib create -fs hdfs://ec2-52-91-50-127.compute-1.amazonaws.com:9000

  setting CATALINA_OPTS="$CATALINA_OPTS -Xmx1024m"
log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/oozie-4.1/libtools/slf4j-simple-1.6.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/oozie-4.1/libtools/slf4j-log4j12-1.6.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/oozie-4.1/libext/slf4j-log4j12-1.6.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.SimpleLoggerFactory]
the destination path for sharelib is: /user/ubuntu/share/lib/lib_20161209182912


# update oozie-site.xml under OOZIE_CONF_DIR

<property>
        <name>oozie.service.HadoopAccessorService.hadoop.configurations</name>
        <value>*=/usr/local/hadoop/etc/hadoop</value>
        <description>
            Comma separated AUTHORITY=HADOOP_CONF_DIR, where AUTHORITY is the HOST:PORT of
            the Hadoop service (JobTracker, HDFS). The wildcard '*' configuration is
            used when there is no exact match for an authority. The HADOOP_CONF_DIR contains
            the relevant Hadoop *-site.xml files. If the path is relative is looked within
            the Oozie configuration directory; though the path can be absolute (i.e. to point
            to Hadoop client conf/ directories in the local filesystem.
        </description>
    </property>

    <property>
        <name>oozie.service.WorkflowAppService.system.libpath</name>
        <value>/user/ubuntu/share/lib</value>
        <description>
            System library path to use for workflow applications.
            This path is added to workflow application if their job properties sets
            the property 'oozie.use.system.libpath' to true.
        </description>
    </property>


# Create oozie database 
ooziedb.sh create -sqlfile oozie.sql -run

# Start Oozie Service
oozied.sh start

# Verify status of Oozie service
oozie admin --oozie http://localhost:11000/oozie -status


* Created jar file using eclipse export

# Create ~/map-reduce
# Create ~/map-reduce/lib
# Create input directory /user/ubuntu/input on HDFS

hdfs dfs -mkdir input

# Copy job.properties and workflow.xml into ~/map-reduce
# Copy jar file into ~/map-reduce/lib
# Copy Flight data into HDFS (/user/ubuntu/input)

# Copy ~/map-reduce into HDFS 

hdfs dfs -put ~/map-reduce map-reduce

#run
oozie job -oozie http://localhost:11000/oozie -config ~/map-reduce/job.properties -run


